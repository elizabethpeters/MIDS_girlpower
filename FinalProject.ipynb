{
 "metadata": {
  "name": "",
  "signature": "sha256:169197cea71028a8579423e712f9e028027272fc996ce6bfdf30addde2456ace"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Final Project notebook"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "\n",
      "#Libraries\n",
      "import re\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# SK-learn libraries for learning.\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn.pipeline import Pipeline\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.naive_bayes import BernoulliNB\n",
      "from sklearn.naive_bayes import MultinomialNB\n",
      "from sklearn.grid_search import GridSearchCV\n",
      "\n",
      "# SK-learn libraries for evaluation.\n",
      "from sklearn.metrics import confusion_matrix\n",
      "from sklearn import metrics\n",
      "from sklearn.metrics import classification_report\n",
      "\n",
      "import csv\n",
      "import fileinput\n",
      "import sys"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 73
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# splits datetime value in form \"2011-01-20 05:00:00\" to 6 columns ['2011' '01' '01' '00' '00' '00']\n",
      "# which allows us to convert the np array to type float and to build a model that includes values in these columns\n",
      "def datetime_split(header_row, data, datetime_index):\n",
      "    header_row = np.insert(np.delete(header_row, datetime_index), 0, [\"year\",\"month\",\"day\",\"hours\",\"mins\",\"secs\"])\n",
      "    # uses the datetime column's index value as a reference around which to stack the columns\n",
      "    # also splits the value around any non a-zA-Z0-9_ characters\n",
      "    split_data = np.hstack((map(lambda x:  re.findall(r\"[\\w']+\", x), data[:,datetime_index]), data[:,:datetime_index],data[:,datetime_index+1:]))\n",
      "    return header_row, split_data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 74
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#import data\n",
      "#numpy loadtxt can only import homogeneous types, so everything has been imported as str\n",
      "\n",
      "#day header \n",
      "#instant,dteday,season,yr,mnth,holiday,weekday,workingday,weathersit,temp,atemp,hum,windspeed,casual,registered,cnt\n",
      "day = np.loadtxt('Bike-Sharing-Dataset/day.csv', dtype=str, delimiter=',', skiprows=1)\n",
      "#print day[0]\n",
      "\n",
      "#hour header\n",
      "#instant,dteday,season,yr,mnth,hr,holiday,weekday,workingday,weathersit,temp,atemp,hum,windspeed,casual,registered,cnt\n",
      "hour = np.loadtxt('Bike-Sharing-Dataset/hour.csv', dtype=str, delimiter=',', skiprows=1)\n",
      "#print hour[0]\n",
      "\n",
      "# ------------------- FETCH MODEL-BUILDING DATA AND CLEAN ---------------------------\n",
      "\n",
      "# Pull data from Kaggle site (https://www.kaggle.com/c/bike-sharing-demand/data)\n",
      "data = np.loadtxt(\"Bike-Sharing-Dataset/train.csv\", dtype=str, delimiter=',')\n",
      "\n",
      "# pass the header row, data, and datetime column index into the datetime_split function to separate the datetime column\n",
      "# into analyzable column values and to convert the array into type float64\n",
      "header_row, data = datetime_split(data[0], data[1:], 0)\n",
      "\n",
      "# create train and test set using cross validation and data shuffling (see sklearn.cross_validation.train_test_split)\n",
      "train, test = train_test_split(data, test_size=0.2, random_state=42)\n",
      "\n",
      "# now make train_labels and test_labels\n",
      "header = header_row[range(14)]\n",
      "header_labels = header_row[range(14,17)]\n",
      "train_labels = train[:, range(14,17)]\n",
      "train = train[:, range(14)]\n",
      "test_labels = test[:, range(14,17)]\n",
      "test = test[:, range(14)]\n",
      "\n",
      "# ------------------- FETCH DEV DATA AND CLEAN ---------------------------\n",
      "\n",
      "# This data has no columns ['casual','registered','count'] since those are what we are trying to predict\n",
      "dev = np.loadtxt('Bike-Sharing-Dataset/test.csv', dtype=str, delimiter=',')\n",
      "# store the header values in an array and remove header row from training data\n",
      "\n",
      "dev_header, dev = datetime_split(dev[0], dev[1:], 0)\n",
      "\n",
      "# ---------------- RESULTING VARIABLES AVAILABLE ------------------\n",
      "\n",
      "# this is a list of variables for us to use: (semicolon at the end supresses annoying output of block comment... don't put anything after it)\n",
      "'''\n",
      "    header, dev_header: contain the column names for variables we will use to build models (should be the same) \n",
      "                        values are ['year' 'month' 'day' 'hours' 'mins' 'secs' 'season' 'holiday' 'workingday' 'weather' 'temp' 'atemp' 'humidity' 'windspeed']\n",
      "    header_labels: contains the column_names for the variables we will need to predict\n",
      "                    values are ['casual' 'registered' 'count']\n",
      "    train: data values we will use to train our model, which has shape (8708,14)\n",
      "    train_labels: data labels we will use to train our model, which has shape (8708, 3)\n",
      "    test: data values we will use to test our model predictions, with shape (2178, 14)\n",
      "    test_labels: data labels we will use to find the accuracy of our model predictions, with shape (2178, 3)\n",
      "    dev: data we need to submit our model's accuracy to Kaggle, with shape (6493, 14)\n",
      "    \n",
      "'''; "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(6493, 14)\n"
       ]
      }
     ],
     "prompt_number": 96
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Individual data exploration in blocks below"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Elizabeth\n",
      "regression and other data exploration"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Erin\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Sharon\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Group discussion"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}