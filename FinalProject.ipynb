{
 "metadata": {
  "name": "",
  "signature": "sha256:042f57f322cbfe827b6ecf327b163545f0baa7840bf130c931d54b3a80831e5c"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Modeling Capital Bike Share Demand"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "\n",
      "#Libraries\n",
      "import re\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# SK-learn libraries for learning.\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn.pipeline import Pipeline\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.naive_bayes import BernoulliNB\n",
      "from sklearn.naive_bayes import MultinomialNB\n",
      "from sklearn.grid_search import GridSearchCV\n",
      "\n",
      "# SK-learn libraries for evaluation.\n",
      "from sklearn.metrics import confusion_matrix\n",
      "from sklearn import metrics\n",
      "from sklearn.metrics import classification_report\n",
      "\n",
      "import csv\n",
      "import fileinput\n",
      "import sys"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 73
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here we define utility function that will be used in the script."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# splits datetime value in form \"2011-01-20 05:00:00\" to 6 columns ['2011' '01' '01' '00' '00' '00']\n",
      "# which allows us to convert the np array to type float and to build a model that includes values in these columns\n",
      "def datetime_split(header_row, data, datetime_index):\n",
      "    header_row = np.insert(np.delete(header_row, datetime_index), 0, [\"year\",\"month\",\"day\",\"hours\",\"mins\",\"secs\"])\n",
      "    # uses the datetime column's index value as a reference around which to stack the columns\n",
      "    # also splits the value around any non a-zA-Z0-9_ characters\n",
      "    split_data = np.hstack((map(lambda x:  re.findall(r\"[\\w']+\", x), data[:,datetime_index]), data[:,:datetime_index],data[:,datetime_index+1:]))\n",
      "    return header_row, split_data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 74
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we begin importing our data and storing it into the proper variable objects that will make it possible to train and test our models. First we download the train and test csv files from Kaggle. Then we cleaned the datetime variable so that it is stored as 6 columns ['2011' '01' '01' '00' '00' '00'] rather than \"2011-01-20 05:00:00\". This allows us to use the variable values as floats rather than string values (which is better for comparison in some cases). We then can split the data into training, test, and dev data along with their respective labels. We also store the header row from the CSV files for later reference."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#import data\n",
      "#numpy loadtxt can only import homogeneous types, so everything has been imported as str\n",
      "\n",
      "#day header \n",
      "#instant,dteday,season,yr,mnth,holiday,weekday,workingday,weathersit,temp,atemp,hum,windspeed,casual,registered,cnt\n",
      "day = np.loadtxt('Bike-Sharing-Dataset/day.csv', dtype=str, delimiter=',', skiprows=1)\n",
      "#print day[0]\n",
      "\n",
      "#hour header\n",
      "#instant,dteday,season,yr,mnth,hr,holiday,weekday,workingday,weathersit,temp,atemp,hum,windspeed,casual,registered,cnt\n",
      "hour = np.loadtxt('Bike-Sharing-Dataset/hour.csv', dtype=str, delimiter=',', skiprows=1)\n",
      "#print hour[0]\n",
      "\n",
      "# ------------------- FETCH MODEL-BUILDING DATA AND CLEAN ---------------------------\n",
      "\n",
      "# Pull data from Kaggle site (https://www.kaggle.com/c/bike-sharing-demand/data)\n",
      "data = np.loadtxt(\"Bike-Sharing-Dataset/train.csv\", dtype=str, delimiter=',')\n",
      "\n",
      "# pass the header row, data, and datetime column index into the datetime_split function to separate the datetime column\n",
      "# into analyzable column values and to convert the array into type float64\n",
      "header_row, data = datetime_split(data[0], data[1:], 0)\n",
      "\n",
      "# create train and test set using cross validation and data shuffling (see sklearn.cross_validation.train_test_split)\n",
      "train, test = train_test_split(data, test_size=0.2, random_state=42)\n",
      "\n",
      "# now make train_labels and test_labels\n",
      "header = header_row[range(14)]\n",
      "header_labels = header_row[range(14,17)]\n",
      "train_labels = train[:, range(14,17)]\n",
      "train = train[:, range(14)]\n",
      "test_labels = test[:, range(14,17)]\n",
      "test = test[:, range(14)]\n",
      "\n",
      "# ------------------- FETCH DEV DATA AND CLEAN ---------------------------\n",
      "\n",
      "# This data has no columns ['casual','registered','count'] since those are what we are trying to predict\n",
      "dev = np.loadtxt('Bike-Sharing-Dataset/test.csv', dtype=str, delimiter=',')\n",
      "# store the header values in an array and remove header row from training data\n",
      "\n",
      "dev_header, dev = datetime_split(dev[0], dev[1:], 0)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 97
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we have the following variables available for use:\n",
      "\n",
      "- **header, dev_header**: contain the column names for variables we will use to build models (should be the same) \n",
      "  - *values are ['year' 'month' 'day' 'hours' 'mins' 'secs' 'season' 'holiday' 'workingday' 'weather' 'temp' 'atemp' 'humidity' 'windspeed']*\n",
      "- **header_labels**: contains the column_names for the variables we will need to predict\n",
      "  - *values are ['casual' 'registered' 'count']*\n",
      "- **train**: data values we will use to train our model, which has shape (8708,14)\n",
      "- **train_labels**: data labels we will use to train our model, which has shape (8708, 3)\n",
      "- **test**: data values we will use to test our model predictions, with shape (2178, 14)\n",
      "- **test_labels**: data labels we will use to find the accuracy of our model predictions, with shape (2178, 3)\n",
      "- **dev**: data we need to submit our model's accuracy to Kaggle, with shape (6493, 14)\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Individual data exploration in blocks below"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Elizabeth\n",
      "regression and other data exploration"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Erin\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Sharon\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Group discussion"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}